# -*- coding: utf-8 -*-
"""movielen-1m.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jqusRIcTQzZsSAbJRhYm5lFo1wcVKW5J
"""

import numpy as np
import pandas as pd
from scipy.sparse import csr_matrix
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics import mean_squared_error
from collections import defaultdict

r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']
ratings_df=pd.read_csv('/content/ratings.dat', sep='::', names=r_cols, engine='python', encoding='latin-1')

##encode rating 0-1
ratings_df['rating_bin'] = np.where(ratings_df['rating'] >= 4, 1, 0)
ratings_df = ratings_df.dropna(subset=["user_id", "movie_id", "rating"])

u = (ratings_df["user_id"].to_numpy(dtype=np.int32) - 1)
i = (ratings_df["movie_id"].to_numpy(dtype=np.int32) - 1)
r = ratings_df["rating_bin"].to_numpy(dtype=np.int8)


n_users = int(u.max()) + 1
n_items = int(i.max()) + 1

Y_data = np.stack([u, i, r], axis=1) # shape (N, 3)
print(f"Users={n_users}, Items={n_items}, Interactions={len(Y_data)}")

Y_data = ratings_df[['user_id', 'movie_id', 'rating_bin']].to_numpy()
Y_data[:, :2] -= 1

# ---------- 4) Train/Test split by user ----------
def split_by_user(Y, test_ratio=0.2, seed=42):
    rng = np.random.default_rng(seed)
    user_rows = defaultdict(list)
    for uu, ii, rr in Y:
        user_rows[int(uu)].append((int(uu), int(ii), int(rr)))

    train, test = [], []
    for uu, rows in user_rows.items():
        if len(rows) < 2:
            train.extend(rows)
            continue

        n_test = max(1, int(len(rows) * test_ratio))
        test_idx = set(rng.choice(len(rows), size=n_test, replace=False).tolist())

        for idx, triplet in enumerate(rows):
            if idx in test_idx:
                test.append(triplet)
            else:
                train.append(triplet)

    return np.array(train, dtype=np.int32), np.array(test, dtype=np.int32)

nan_mask = np.isnan(Y_data[:, 0]) | np.isnan(Y_data[:, 1])
Y_data_cleaned = Y_data[~nan_mask].astype(np.int32)
Y_train, Y_test = split_by_user(Y_data_cleaned, test_ratio=0.2, seed=42)
print(f"Train={len(Y_train)} | Test={len(Y_test)}")

# ---------- 5) Build sparse R_train ----------
R_train = csr_matrix(
    (Y_train[:, 2].astype(np.float32),
     (Y_train[:, 0], Y_train[:, 1])),
    shape=(n_users, n_items),
    dtype=np.float32
)

# ---------- 6) Train MF via TruncatedSVD ----------
K = 50
svd = TruncatedSVD(n_components=K, random_state=42)
U = svd.fit_transform(R_train)        # shape (n_users, K)  (đã "gồm Sigma" bên trong theo sklearn)
Vt = svd.components_                  # shape (K, n_items)

# ---------- 7) Prepare sets for evaluation ----------
# Items seen in TRAIN (exclude from recommendation list)
user_seen = defaultdict(set)
for uu, ii, rr in Y_train:
    user_seen[int(uu)].add(int(ii))

# Positive items in TEST (ground truth relevant)
user_pos_test = defaultdict(set)
for uu, ii, rr in Y_test:
    if int(rr) == 1:
        user_pos_test[int(uu)].add(int(ii))

# ---------- 8) Metrics ----------
def precision_at_k(ranked_items, relevant_items, k):
    if k <= 0:
        return 0.0
    hit = 0
    for item in ranked_items[:k]:
        if item in relevant_items:
            hit += 1
    return hit / k

def ndcg_at_k(ranked_items, relevant_items, k):
    dcg = 0.0
    for idx, item in enumerate(ranked_items[:k]):
        if item in relevant_items:
            dcg += 1.0 / np.log2(idx + 2)   # idx starts 0 -> log2(2)=1
    ideal_hits = min(len(relevant_items), k)
    if ideal_hits == 0:
        return 0.0
    idcg = sum(1.0 / np.log2(i + 2) for i in range(ideal_hits))
    return dcg / idcg

def topk_rank_for_user(uu, k=10):
    """
    Tạo ranking top-k cho user uu:
    score = U[uu] @ Vt  -> vector length n_items
    rồi loại các item đã seen trong train.
    """
    scores = U[uu] @ Vt  # (n_items,)
    seen = user_seen.get(uu, set())
    if seen:
        scores = scores.copy()
        scores[list(seen)] = -np.inf

    # Lấy top-k nhanh (không sort toàn bộ)
    if k >= len(scores):
        return np.argsort(scores)[::-1]
    idx_part = np.argpartition(scores, -k)[-k:]
    idx_sorted = idx_part[np.argsort(scores[idx_part])[::-1]]
    return idx_sorted

# ---------- 9) Evaluate Precision@5/10, NDCG@5/10 ----------
def evaluate(k_list=(5, 10)):
    results = {f"Precision@{k}": [] for k in k_list}
    results.update({f"NDCG@{k}": [] for k in k_list})

    users_evaluated = 0
    for uu, rel_items in user_pos_test.items():
        if not rel_items:
            continue

        users_evaluated += 1
        max_k = max(k_list)
        ranked_top = topk_rank_for_user(uu, k=max_k)

        for k in k_list:
            results[f"Precision@{k}"].append(precision_at_k(ranked_top, rel_items, k))
            results[f"NDCG@{k}"].append(ndcg_at_k(ranked_top, rel_items, k))

    # average
    avg = {m: float(np.mean(v)) if len(v) else 0.0 for m, v in results.items()}
    return avg, users_evaluated

metrics, n_eval_users = evaluate(k_list=(5, 10))
print(f"Evaluated users (have at least 1 positive in test): {n_eval_users}")
for name, val in metrics.items():
    print(f"{name}: {val:.4f}")